My git repository data was too big to fit under the single 1MB file restriction on the Moodle assignment page, so it's not in this archive, but it's available in a public git repository at https://bitbucket.org/kcsmnt0/chextensible-essfects.

Building this project on the department Linux machines is a little complicated. Sorry! You'll need GHC8 and a few libraries; it's easiest to build with stack, which takes care of that all seamlessly, but you'll need to install a local copy of a more recent version of stack than the Linux machines have installed. Run "stack upgrade" from any directory, then find the updated stack binary at ~/.local/bin/stack and use it to run "stack build" from this directory (i.e. run "~/.local/bin/stack build" or add ~/.local/bin to your PATH and run "stack build"). "stack exec chess" runs the program, or you can find the binary at .stack-work/dist/x86_64-linux/Cabal-1.24.2.0/build/chess/chess (modulo platform or version string differences).

This is a little bit of a mad science experiment. Having settled on Haskell for my agent, I assumed up front that I wouldn't be winning any performance shoot-outs, so I decided to focus on building a solid framework that would let me prototype agents quickly and run them against each other. One thing led to another and I ultimately ended up pulling in an experimental library for extensible effect handling and enabling like two dozen language extensions, so this code can be a little cryptic in some parts, but it's been a lot of fun to work on and I think with some documentation and a bunch of cleanup it has the potential to be fairly approachable as far as Haskell programs go. (Sorry you get the less approachable version to grade, it's just a matter of time constraints.)

Chess.hs contains definitions for the rules of chess, the definition of the Agent type, and the playGame function, which runs a game between two agents to completion. Agent/Console.hs has comments that explain the pattern I'm using for constructing agents, and the other agents are commented where they make interesting changes on that formula. Control/Monad/Freer contains some effects that the agents depend on in addition to the ones included in the freer-effects library, and some commands for setting up games with IMCS over the Socket effect are defined in IMCS.hs. The Scripts directory has some functions that set up and execute games between particular agents (and is probably the sloppiest part of the code, a lot of it is copied and pasted). Grid.hs defines a general interface for 2D grids, which is meant to support experimentation with different board representations, but right now Grid/Array.hs is the only reasonable one. Main.hs is set up to run a script that asks the user via the console to sign into the IMCS and choose an open game offer to accept (enter a 0-based list index), and then run the negamax agent against that opponent.

The missing required features at the moment are transposition tables and the ability to offer an IMCS game, both of which I plan to finish before the resubmission deadline. The source is littered with todo comments that give a picture of what else I have planned - I definitely intend to keep working on this for fun and experience after the quarter is over - but in brief, given two more weeks I would focus first on unit tests and code cleanup and then move on to fleshing out the AI agent's feature set.

Performance is adequate but not spectacular; ultimately, most of my energy so far has gone into making a functioning agent with the minimum required feature set and I haven't had much leftover time to add optional improvements. I've been pitting the agent against myself (through IMCS via telnet) and other IMCS bots, and it doesn't play too stupidly most of the time - it can beat me reliably, but that's not saying much - but I don't expect to make it very far in the tournament. I think shortest-win prioritization would be a big improvement, since the agent seems generally content to wait until the last minute to clinch a victory even when it's clearly ahead, and I suspect that the naivety of the board evaluation function (Chess.boardScore) is what leaves the agent bumbling around at the start of the game before the opponent presents a threat, so I'm thinking I'll try tweaking it to prioritize the advancement of some pieces. The time management is basically a hack to aim for roughly 7.5 seconds per turn; the time taken by the code outside of the negamax search can't really be deterministically predicted, so that whole construct is a little sketchy. I tried a little adaptive time management experiment and found that keeping track of time within agent code (with system time calls) was pretty error-prone, so my next attempt at that is going to just use the time the server reports, which is really much simpler anyway.

Testing has been done entirely by hand in a REPL, which is a bit embarrassing to admit to, but monadic effects really do make testing by hand pretty nice; I just mocked up state and network sessions by hand for ad-hoc unit testing. Integration testing has mostly been against TacklingBot.


Having (hopefully) fulfilled the technical requirements for this writeup, I feel like the Agent type and use of the freer-effects library might warrant a bit of motivation and clarification. My goal was to be able to write a agents depending individually on arbitrary sets of effects and be able to pit instances of two different agents against each other in a context supporting the union of both agents' effects. The common Haskell solution for handling multiple effects polymorphically, as implemented by the mtl and transformers libraries, isn't particularly elegant for this purpose - the MonadState typeclass, for instance, has a functional dependency enforcing that no single type variable representing a monad can be used for two different types of monadic state. (Incidentally, Dr. Jones says that he's sometimes cited as the source of the argument in favor of that restriction, but that that's a misattribution and he's actually in favor of removing it.) I could have done everything in IO with IOVars and stuff, but I wanted a more fine-grained and flexible solution, and I could have used custom monad transformers for each agent, but that brings ordering concerns into play (transformers aren't necessarily commutative) and introduces lots of boilerplate.

The freer-effects library basically tags computations with type-level lists of effects (e.g. Choice, State s) that they depend on and eliminate the effects flexibly with handlers (e.g. runChoices, execState) at the call sites. Each agent then gets to come bundled with its own effect requirements, and the playGame function in Chess.hs interleaves the effect handling for the two agents; the scripts ultimately interpret these interleaved competition descriptions as IO commands.

Effect handling in this framework is still monadic, but instead of stacking monad transformers to compose effects, library functions mechanically combine the definitions of multiple functorial effects into a single monad. In the code, this is represented as "Eff effs a": a computation that returns a value of type "a" operating with (only) the effects in the list "effs". The "Member" constraint requires that a certan effect is present in a list, which licenses the implementation of a function to use the functions that come along with that effect, like "consoleWrite" or "choose".
